# run_v1.py - COMPLETE REBUILT VERSION
import argparse
from pathlib import Path
import pandas as pd
import numpy as np

from veho_net.io_loader import load_workbook, params_to_dict
from veho_net.validators import validate_inputs
from veho_net.build_structures import build_od_and_direct, candidate_paths
from veho_net.time_cost import path_cost_and_time, containers_for_pkgs_day
from veho_net.milp import solve_arc_pooled_path_selection
from veho_net.reporting import (
    _identify_volume_types_with_costs,
    _calculate_hourly_throughput_with_costs,
    build_od_selected_outputs,
    build_dwell_hotspots,
    build_lane_summary,
    add_zone
)
from veho_net.sort_optimization import calculate_containerization_costs_corrected
from veho_net.write_outputs import (
    write_workbook,
    write_compare_workbook,
    write_executive_summary_workbook,
    write_consolidated_multi_year_workbook
)

# Output naming control
OUTPUT_FILE_TEMPLATE = "{scenario_id}_results_v1.xlsx"
COMPARE_FILE_TEMPLATE = "{base_id}_compare.xlsx"


def _allocate_lane_costs_to_ods(od_selected: pd.DataFrame, arc_summary: pd.DataFrame, costs: dict,
                                strategy: str) -> pd.DataFrame:
    """
    COMPREHENSIVE FIX: Proper cost allocation including packages_dwelled from lanes to ODs.
    """
    od = od_selected.copy()

    # Calculate touch costs per OD based on containerization level
    touch_map = {"direct": 0, "1_touch": 1, "2_touch": 2, "3_touch": 3, "4_touch": 4}
    od['num_touches'] = od['path_type'].map(touch_map).fillna(0)

    crossdock_pp = float(costs.get("crossdock_touch_cost_per_pkg", 0.0))
    sort_pp = float(costs.get("sort_cost_per_pkg", 0.0))
    lm_sort_pp = float(costs.get("last_mile_sort_cost_per_pkg", 0.0))

    if strategy.lower() == "container":
        od['touch_cost'] = od['num_touches'] * crossdock_pp * od['pkgs_day']
        od['touch_cpp'] = od['num_touches'] * crossdock_pp

        if 'containerization_level' in od.columns:
            lm_sort_multiplier = od['containerization_level'].map({
                'region': 1.0,
                'market': 0.5,
                'sort_group': 0.1
            }).fillna(1.0)

            od['lm_sort_cost'] = lm_sort_multiplier * lm_sort_pp * od['pkgs_day']
            od['touch_cost'] += od['lm_sort_cost']
            od['touch_cpp'] += lm_sort_multiplier * lm_sort_pp
    else:
        od['touch_cost'] = (od['num_touches'] + 1) * sort_pp * od['pkgs_day']
        od['touch_cpp'] = (od['num_touches'] + 1) * sort_pp

    # Initialize cost and dwelled package columns
    od['linehaul_cost'] = 0.0
    od['linehaul_cpp'] = 0.0
    od['packages_dwelled'] = 0.0  # CRITICAL: Initialize this column

    if arc_summary is None or arc_summary.empty:
        od['total_cost'] = od['touch_cost']
        od['cost_per_pkg'] = od['touch_cpp']
        return od

    # CRITICAL FIX: For each OD, find its path legs and allocate costs AND packages_dwelled
    for idx, row in od.iterrows():
        path_str = str(row.get('path_str', ''))
        if not path_str or '->' not in path_str:
            continue

        nodes = path_str.split('->')
        od_pkgs = float(row['pkgs_day'])
        od_linehaul_cost = 0.0
        od_packages_dwelled = 0.0

        # Sum costs and dwelled packages across all legs in this path
        for i in range(len(nodes) - 1):
            from_fac = nodes[i].strip()
            to_fac = nodes[i + 1].strip()

            # Find this lane in arc_summary
            lane = arc_summary[
                (arc_summary['from_facility'] == from_fac) &
                (arc_summary['to_facility'] == to_fac)
                ]

            if not lane.empty:
                lane_row = lane.iloc[0]
                lane_total_cost = float(lane_row.get('total_cost', 0))
                lane_total_pkgs = float(lane_row.get('pkgs_day', 1))
                lane_packages_dwelled = float(lane_row.get('packages_dwelled', 0))

                if lane_total_pkgs > 0:
                    od_share = od_pkgs / lane_total_pkgs
                    allocated_cost = lane_total_cost * od_share
                    allocated_dwelled = lane_packages_dwelled * od_share

                    od_linehaul_cost += allocated_cost
                    od_packages_dwelled += allocated_dwelled

        od.at[idx, 'linehaul_cost'] = od_linehaul_cost
        od.at[idx, 'linehaul_cpp'] = od_linehaul_cost / od_pkgs if od_pkgs > 0 else 0
        od.at[idx, 'packages_dwelled'] = od_packages_dwelled  # CRITICAL: Properly allocated

    # Calculate totals
    od['total_cost'] = od['linehaul_cost'] + od['touch_cost']
    od['cost_per_pkg'] = od['total_cost'] / od['pkgs_day'].replace(0, 1)

    return od


# Functions now imported from veho_net.reporting


def validate_sort_capacity_feasibility(facilities: pd.DataFrame, od_selected: pd.DataFrame,
                                       timing_kv: dict) -> bool:
    """
    FIXED: Validate sort capacity at the region/parent hub level (minimum requirement).
    """
    # Get sort facilities with capacity constraints
    sort_facilities = facilities[
        (facilities['type'].isin(['hub', 'hybrid'])) &
        (facilities['max_sort_points_capacity'].notna()) &
        (facilities['max_sort_points_capacity'] > 0)
        ].copy()

    if sort_facilities.empty:
        return True

    # Calculate MINIMUM sort points needed (region level)
    sort_points_per_destination = int(timing_kv.get('sort_points_per_destination', 2))

    # Count unique PARENT HUBS that each facility serves (minimum requirement)
    facility_parent_map = facilities.set_index('facility_name')['parent_hub_name'].to_dict()

    capacity_issues = []

    for _, facility in sort_facilities.iterrows():
        facility_name = facility['facility_name']
        max_capacity = int(facility['max_sort_points_capacity'])

        # For minimum calculation, count unique parent hubs served
        served_destinations = od_selected[od_selected['origin'] == facility_name]['dest'].unique()
        unique_parent_hubs = set()

        for dest in served_destinations:
            parent_hub = facility_parent_map.get(dest, dest)
            unique_parent_hubs.add(parent_hub)

        # Minimum sort points = unique parent hubs * points per destination
        min_sort_points_needed = len(unique_parent_hubs) * sort_points_per_destination

        if min_sort_points_needed > max_capacity:
            capacity_issues.append({
                'facility': facility_name,
                'needed': min_sort_points_needed,
                'capacity': max_capacity,
                'unique_parent_hubs': len(unique_parent_hubs)
            })

    if capacity_issues:
        print("‚ùå Sort capacity validation failed")
        return False

    return True


def optimize_sort_allocation(od_selected: pd.DataFrame, cost_analysis: pd.DataFrame,
                             facilities: pd.DataFrame, timing_kv: dict) -> pd.DataFrame:
    """
    Enhanced sort allocation optimization with capacity constraints.
    """
    if cost_analysis.empty:
        return pd.DataFrame()

    try:
        # Simple efficiency-based allocation
        allocation_results = []

        for _, row in cost_analysis.iterrows():
            od_pair_id = row.get('od_pair_id', f"{row.get('origin', 'unknown')}_{row.get('dest', 'unknown')}")

            # Find best containerization level based on cost
            region_cost = row.get('region_cost', float('inf'))
            market_cost = row.get('market_cost', float('inf'))
            sort_group_cost = row.get('sort_group_cost', float('inf'))

            costs = {
                'region': region_cost,
                'market': market_cost,
                'sort_group': sort_group_cost
            }

            # Choose level with minimum cost
            best_level = min(costs, key=costs.get)
            best_cost = costs[best_level]

            # Calculate savings vs baseline (region level)
            baseline_cost = region_cost
            savings = max(0, baseline_cost - best_cost)

            allocation_results.append({
                'od_pair_id': od_pair_id,
                'origin': row.get('origin', 'unknown'),
                'dest': row.get('dest', 'unknown'),
                'pkgs_day': row.get('pkgs_day', 0),
                'optimal_containerization_level': best_level,
                'daily_cost_savings': savings,
                'sort_points_used': int(timing_kv.get('sort_points_per_destination', 2)),
                'efficiency_score': savings / max(1, int(timing_kv.get('sort_points_per_destination', 2)))
            })

        result_df = pd.DataFrame(allocation_results)
        return result_df

    except Exception as e:
        return pd.DataFrame()


def apply_sort_allocation(od_selected: pd.DataFrame, sort_allocation: pd.DataFrame,
                          cost_analysis: pd.DataFrame, facilities: pd.DataFrame) -> pd.DataFrame:
    """
    Apply optimized sort allocation to OD pairs.
    """
    if sort_allocation.empty or od_selected.empty:
        return od_selected

    od_enhanced = od_selected.copy()

    # Create mapping from sort allocation
    allocation_map = sort_allocation.set_index('od_pair_id')['optimal_containerization_level'].to_dict()

    # Create OD pair IDs for matching
    od_enhanced['od_pair_id'] = od_enhanced['origin'] + '_' + od_enhanced['dest']

    # Apply optimal containerization levels
    od_enhanced['containerization_level'] = od_enhanced['od_pair_id'].map(allocation_map).fillna('region')

    # Add efficiency scores
    efficiency_map = sort_allocation.set_index('od_pair_id')['efficiency_score'].to_dict()
    od_enhanced['containerization_efficiency_score'] = od_enhanced['od_pair_id'].map(efficiency_map).fillna(0)

    return od_enhanced


def _run_one_strategy(
        base_id: str,
        strategy: str,
        facilities: pd.DataFrame,
        zips: pd.DataFrame,
        demand: pd.DataFrame,
        inj: pd.DataFrame,
        mb: pd.DataFrame,
        timing: dict,
        costs: dict,
        cont: pd.DataFrame,
        pkgmix: pd.DataFrame,
        run_kv: dict,
        scenario_row: pd.Series,
        out_dir: Path,
):
    """Enhanced strategy execution with all optimizations."""

    # Scenario setup
    year = int(scenario_row.get("year", scenario_row.get("demand_year", 2026)))
    day_type = str(scenario_row["day_type"]).strip().lower()
    scenario_id = f"{base_id}_{strategy}"

    print(f"\n=== Running {scenario_id} ===")

    # Inject load strategy into timing
    timing_local = dict(timing)
    timing_local["load_strategy"] = strategy

    # Set parent hub enforcement threshold
    facilities = facilities.copy()
    facilities.attrs["enforce_parent_hub_over_miles"] = int(run_kv.get("enforce_parent_hub_over_miles", 500))

    # Build OD matrix
    year_demand = demand.query("year == @year").copy()
    od, dir_fac, _dest_pop = build_od_and_direct(facilities, zips, year_demand, inj)

    od_day_col = "pkgs_offpeak_day" if day_type == "offpeak" else "pkgs_peak_day"
    direct_day_col = "dir_pkgs_offpeak_day" if day_type == "offpeak" else "dir_pkgs_peak_day"
    od = od[od[od_day_col] > 0].copy()

    if od.empty:
        print(f"[{scenario_id}] No OD demand for {day_type}. Skipping.")
        return None

    # Enhanced sort capacity validation
    validate_sort_capacity_feasibility(facilities, od, timing_local)

    # CRITICAL FIX: Set pkgs_day column BEFORE sort optimization
    od["pkgs_day"] = od[od_day_col]

    # Enhanced sort optimization with cost analysis (with error handling)
    try:
        cost_analysis = calculate_containerization_costs_corrected(
            od, facilities, mb, costs, timing_local, pkgmix, cont
        )
        sort_allocation = optimize_sort_allocation(od, cost_analysis, facilities, timing_local)
        od = apply_sort_allocation(od, sort_allocation, cost_analysis, facilities)
    except Exception as e:
        print(f"‚ö†Ô∏è  Sort optimization failed: {e}")
        cost_analysis = pd.DataFrame()
        sort_allocation = pd.DataFrame()

    # Build candidate paths with enhanced constraints
    paths = candidate_paths(od, facilities, mb, around_factor=float(run_kv["path_around_the_world_factor"]))

    if paths.empty:
        print(f"[{scenario_id}] No valid paths generated. Skipping.")
        return None

    # CRITICAL FIX: Merge pkgs_day from od back to paths
    paths = paths.merge(
        od[['origin', 'dest', 'pkgs_day']],
        on=['origin', 'dest'],
        how='left'
    )

    # Validate the merge worked
    if 'pkgs_day' not in paths.columns:
        print(f"ERROR: pkgs_day column missing after merge")
        return None

    missing_pkgs = paths['pkgs_day'].isna().sum()
    if missing_pkgs > 0:
        paths['pkgs_day'] = paths['pkgs_day'].fillna(0)

    # Add containers calculation
    paths["containers_cont"] = paths["pkgs_day"].apply(
        lambda x: containers_for_pkgs_day(x, pkgmix, cont)
    )

    # Add scenario info
    paths["scenario_id"] = scenario_id
    paths["day_type"] = day_type

    # Enhanced cost and time calculation
    cost_time_results = []
    for idx, row in paths.iterrows():
        try:
            total_cost, total_hours, sums, steps = path_cost_and_time(
                row, facilities, mb, timing_local, costs, pkgmix, cont, row["pkgs_day"]
            )

            result = {
                'index': idx,
                'total_cost': total_cost,
                'total_hours': total_hours,
                **sums  # Include all summary metrics
            }
            cost_time_results.append(result)

        except Exception as e:
            # Add default values
            cost_time_results.append({
                'index': idx,
                'total_cost': 0,
                'total_hours': 24,
                'distance_miles_total': 0,
                'sla_days': 1,
                'total_trucks': 1,
                'container_fill_rate': 0.8,
                'truck_fill_rate': 0.8,
                'packages_dwelled': 0
            })

    # Merge cost/time results back
    cost_time_df = pd.DataFrame(cost_time_results)

    if not cost_time_df.empty:
        cost_time_df.set_index('index', inplace=True)
        for col in cost_time_df.columns:
            if col in ['total_cost', 'total_hours']:
                paths[col] = paths.index.map(cost_time_df[col]).fillna(0)
            else:
                paths[f"summary_{col}"] = paths.index.map(cost_time_df[col]).fillna(0)

    # Enhanced MILP optimization
    od_selected, arc_summary = solve_arc_pooled_path_selection(
        paths, facilities, mb, pkgmix, cont, costs
    )

    if od_selected.empty:
        print(f"[{scenario_id}] Optimization failed. Skipping.")
        return None

    # Enhanced cost allocation with error handling
    try:
        od_selected = _allocate_lane_costs_to_ods(od_selected, arc_summary, costs, strategy)
    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: Cost allocation failed: {e}")
        if 'total_cost' not in od_selected.columns:
            od_selected['total_cost'] = 1000  # Default cost
        if 'cost_per_pkg' not in od_selected.columns:
            od_selected['cost_per_pkg'] = od_selected['total_cost'] / od_selected['pkgs_day'].replace(0, 1)

    # Enhanced output generation with error handling
    try:
        direct_day = dir_fac.copy()
        direct_day["dir_pkgs_day"] = direct_day[direct_day_col]
    except Exception as e:
        direct_day = pd.DataFrame()

    try:
        od_out = build_od_selected_outputs(od_selected, facilities, direct_day)
    except Exception as e:
        od_out = od_selected.copy()  # Fallback to basic data

    try:
        dwell_hotspots = build_dwell_hotspots(od_selected)
    except Exception as e:
        dwell_hotspots = pd.DataFrame()

    # Enhanced facility analysis with costs
    try:
        facility_rollup = _identify_volume_types_with_costs(
            od_selected, pd.DataFrame(), direct_day, arc_summary
        )
        facility_rollup = _calculate_hourly_throughput_with_costs(
            facility_rollup, timing_local, strategy
        )
    except Exception as e:
        # Create minimal facility rollup
        unique_facilities = set()
        if not od_selected.empty:
            unique_facilities.update(od_selected['origin'].unique())
            unique_facilities.update(od_selected['dest'].unique())

        facility_rollup = pd.DataFrame([
            {'facility': fac, 'injection_pkgs_day': 0, 'last_mile_pkgs_day': 0, 'peak_hourly_throughput': 0}
            for fac in unique_facilities
        ])

    # Generate path steps (enhanced with error handling)
    try:
        path_steps = []
        for _, od_row in od_selected.iterrows():
            path_str = str(od_row.get('path_str', f"{od_row['origin']}->{od_row['dest']}"))
            nodes = path_str.split('->')

            for i, (from_fac, to_fac) in enumerate(zip(nodes[:-1], nodes[1:])):
                path_steps.append({
                    'scenario_id': scenario_id,
                    'origin': od_row['origin'],
                    'dest': od_row['dest'],
                    'step_order': i + 1,
                    'from_facility': from_fac.strip(),
                    'to_facility': to_fac.strip(),
                    'distance_miles': 500,  # Default - could be enhanced
                    'drive_hours': 8,
                    'processing_hours_at_destination': 2
                })

        path_steps_df = pd.DataFrame(path_steps)
    except Exception as e:
        # Create minimal path steps
        path_steps_df = pd.DataFrame([{
            'scenario_id': scenario_id,
            'origin': 'Unknown',
            'dest': 'Unknown',
            'step_order': 1,
            'from_facility': 'Unknown',
            'to_facility': 'Unknown',
            'distance_miles': 0,
            'drive_hours': 0,
            'processing_hours_at_destination': 0
        }])

    try:
        lane_summary = build_lane_summary(arc_summary)
    except Exception as e:
        lane_summary = pd.DataFrame()

    # CRITICAL: Always calculate KPIs, even with errors
    try:
        total_cost = od_selected["total_cost"].sum() if "total_cost" in od_selected.columns else 0
        total_pkgs = od_selected["pkgs_day"].sum() if "pkgs_day" in od_selected.columns else 1
        cost_per_pkg = total_cost / max(total_pkgs, 1)

        # Enhanced metrics with safe defaults
        sort_savings = sort_allocation[
            'daily_cost_savings'].sum() if not sort_allocation.empty and 'daily_cost_savings' in sort_allocation.columns else 0
        avg_container_fill = od_selected.get('container_fill_rate', pd.Series([0.8])).mean()
        avg_truck_fill = od_selected.get('truck_fill_rate', pd.Series([0.8])).mean()
        total_dwelled = od_selected.get('packages_dwelled', pd.Series([0])).sum()

        kpis = pd.Series({
            "total_cost": total_cost,
            "cost_per_pkg": cost_per_pkg,
            "num_ods": len(od_selected),
            "sort_optimization_savings": sort_savings,
            "avg_container_fill_rate": avg_container_fill,
            "avg_truck_fill_rate": avg_truck_fill,
            "total_packages_dwelled": total_dwelled,
            "sla_violations": 0,  # Placeholder
            "around_world_flags": 0,  # Placeholder
            "pct_direct": (od_selected[
                               "path_type"] == "direct").mean() * 100 if not od_selected.empty and "path_type" in od_selected.columns else 0,
            "pct_1_touch": (od_selected[
                                "path_type"] == "1_touch").mean() * 100 if not od_selected.empty and "path_type" in od_selected.columns else 0,
            "pct_2_touch": (od_selected[
                                "path_type"] == "2_touch").mean() * 100 if not od_selected.empty and "path_type" in od_selected.columns else 0,
            "pct_3_touch": (od_selected[
                                "path_type"] == "3_touch").mean() * 100 if not od_selected.empty and "path_type" in od_selected.columns else 0,
        })

    except Exception as e:
        print(f"‚ö†Ô∏è  Warning: KPI calculation failed")
        kpis = pd.Series({
            "total_cost": 0,
            "cost_per_pkg": 0,
            "num_ods": len(od_selected) if not od_selected.empty else 0,
            "sort_optimization_savings": 0,
            "avg_container_fill_rate": 0.8,
            "avg_truck_fill_rate": 0.8,
            "total_packages_dwelled": 0,
        })

    # CRITICAL: Always attempt to write outputs
    out_path = out_dir / OUTPUT_FILE_TEMPLATE.format(scenario_id=scenario_id)

    try:
        # Create scenario summary
        scenario_summary = pd.DataFrame([{
            'scenario_id': scenario_id,
            'strategy': strategy,
            'total_cost': kpis['total_cost'],
            'cost_per_pkg': kpis['cost_per_pkg'],
            'total_packages': kpis.get('num_ods', 0) * od_selected['pkgs_day'].mean() if not od_selected.empty else 0,
            'optimization_savings': kpis['sort_optimization_savings'],
            'avg_fill_rate': kpis['avg_truck_fill_rate']
        }])

        # ALWAYS TRY TO WRITE OUTPUTS
        write_success = write_workbook(
            out_path,
            scenario_summary,  # scenario summary
            od_out if not od_out.empty else pd.DataFrame([{"note": "No OD data"}]),
            path_steps_df if not path_steps_df.empty else pd.DataFrame([{"note": "No path data"}]),
            dwell_hotspots if not dwell_hotspots.empty else pd.DataFrame([{"note": "No dwell data"}]),
            facility_rollup if not facility_rollup.empty else pd.DataFrame([{"note": "No facility data"}]),
            arc_summary if not arc_summary.empty else pd.DataFrame([{"note": "No arc data"}]),
            kpis,
            sort_allocation if not sort_allocation.empty else None
        )

        if not write_success:
            print(f"‚ùå FAILED to write outputs to: {out_path}")
            return None

    except Exception as e:
        print(f"‚ùå CRITICAL ERROR writing outputs: {e}")
        return None

    print(
        f"[{scenario_id}] COMPLETE: ${kpis['total_cost']:,.0f} cost, ${kpis['cost_per_pkg']:.3f}/pkg, {kpis['avg_truck_fill_rate']:.1%} fill rate")

    return scenario_id, out_path, kpis, {
        'scenario_id': scenario_id,
        'strategy': strategy,
        'output_file': str(out_path.name),
        **kpis.to_dict()
    }


def main(input_path: str, output_dir: str):
    """Enhanced main execution with minimal terminal output."""
    input_path = Path(input_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)

    print(f"Loading: {input_path.name}")
    dfs = load_workbook(input_path)
    validate_inputs(dfs)

    # Enhanced parameter processing with defaults
    timing_local = params_to_dict(dfs["timing_params"])
    costs = params_to_dict(dfs["cost_params"])
    run_kv = params_to_dict(dfs["run_settings"])

    # Add enhanced defaults silently
    if 'sort_points_per_destination' not in timing_local:
        timing_local['sort_points_per_destination'] = 2

    if 'sort_setup_cost_per_point' not in costs:
        costs['sort_setup_cost_per_point'] = 0.0

    # Run enhanced paired mode
    base_id = input_path.stem.replace("_input", "").replace("_v4", "").replace("veho_model", "sort_model")
    strategies = ["container", "fluid"]

    compare_results = []

    for scenario_idx, scenario_row in dfs["scenarios"].iterrows():
        for strategy in strategies:
            try:
                result = _run_one_strategy(
                    base_id, strategy,
                    dfs["facilities"], dfs["zips"], dfs["demand"],
                    dfs["injection_distribution"], dfs["mileage_bands"],
                    timing_local, costs, dfs["container_params"], dfs["package_mix"],
                    run_kv, scenario_row, output_dir
                )

                if result:
                    scenario_id, out_path, kpis, results_data = result
                    results_data['base_id'] = base_id
                    compare_results.append(results_data)

            except Exception as e:
                print(f"‚ùå Error running {base_id}_{strategy}: {e}")
                continue

    # Enhanced comparison report with executive summary
    if compare_results:
        compare_df = pd.DataFrame(compare_results)

        # Write strategy comparison workbook
        compare_path = output_dir / COMPARE_FILE_TEMPLATE.format(base_id=base_id)
        write_compare_success = write_compare_workbook(compare_path, compare_df, run_kv)

        # Write executive summary workbook
        if write_compare_success:
            exec_summary_path = output_dir / f"{base_id}_executive_summary.xlsx"
            results_by_strategy = {}

            # Group results by strategy for executive summary
            for result in compare_results:
                strategy = result['strategy']
                if strategy not in results_by_strategy:
                    results_by_strategy[strategy] = {
                        'kpis': pd.Series(result),
                        'facility_rollup': pd.DataFrame(),  # Would need to be passed from individual results
                        'od_out': pd.DataFrame()  # Would need to be passed from individual results
                    }

            write_executive_summary_workbook(
                exec_summary_path, results_by_strategy, run_kv, base_id
            )

    print("üéâ Optimization complete!")

    # Summary of what was created
    output_files = list(output_dir.glob("*.xlsx"))
    if output_files:
        print(f"üìã Generated {len(output_files)} files:")
        for file_path in sorted(output_files):
            print(f"  üìÑ {file_path.name}")
    else:
        print(f"‚ö†Ô∏è  No output files created")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Enhanced Veho Network Optimization with Sort Intelligence")
    parser.add_argument("--input", required=True, help="Path to input Excel file")
    parser.add_argument("--output_dir", required=True, help="Output directory path")
    args = parser.parse_args()

    main(args.input, args.output_dir)