# veho_net/sort_optimization.py - FIXED VERSION with correct containerization level validation
import pandas as pd
import numpy as np
from typing import Dict, Tuple, List
from .geo import haversine_miles, band_lookup


def validate_sort_capacity_feasibility(facilities: pd.DataFrame, od_selected: pd.DataFrame,
                                       timing_kv: dict) -> None:
    """
    FIXED: Validation with minimum sort point calculation at REGION level (least granular).

    Containerization levels:
    - Region: Least granular (minimum requirement)
    - Market: Middle granularity
    - Sort Group: Most granular
    """
    try:
        capacity_warnings = []
        sort_points_per_dest = int(timing_kv.get('sort_points_per_destination', 2))

        # Get origins safely
        if od_selected.empty or 'origin' not in od_selected.columns:
            print("Warning: No origins found in OD data for validation")
            return

        origin_facilities = od_selected['origin'].unique()

        # Build parent hub lookup for destinations (region-level consolidation)
        dest_to_parent = {}
        for _, facility in facilities.iterrows():
            facility_name = facility['facility_name']
            parent_hub = facility.get('parent_hub_name')
            if pd.isna(parent_hub) or parent_hub == "":
                parent_hub = facility_name
            dest_to_parent[facility_name] = parent_hub

        for facility_name in origin_facilities:
            try:
                facility_row = facilities[facilities['facility_name'] == facility_name]
                if facility_row.empty:
                    continue

                facility = facility_row.iloc[0]

                # Skip if not hub/hybrid
                if facility.get('type') not in ['hub', 'hybrid']:
                    continue

                # FIXED: Calculate minimum based on unique REGIONS (parent hubs) served
                facility_ods = od_selected[od_selected['origin'] == facility_name]

                # Map destinations to their parent hubs (regions)
                destination_regions = set()
                for dest in facility_ods['dest'].unique():
                    parent_hub = dest_to_parent.get(dest, dest)
                    destination_regions.add(parent_hub)

                # Remove self if present (can't route to yourself)
                own_parent = dest_to_parent.get(facility_name, facility_name)
                destination_regions.discard(facility_name)
                destination_regions.discard(own_parent)

                # Minimum requirement: unique regions Ã— sort points per destination
                unique_regions = len(destination_regions)
                min_required = unique_regions * sort_points_per_dest

                print(
                    f"DEBUG {facility_name}: {len(facility_ods['dest'].unique())} markets â†’ {unique_regions} regions â†’ {min_required} min sort points")

                max_capacity = facility.get('max_sort_points_capacity', None)
                if pd.isna(max_capacity):
                    continue  # Skip facilities without capacity constraints

                max_capacity = int(max_capacity)

                if max_capacity < min_required:
                    capacity_warnings.append(
                        f"{facility_name} needs {min_required} sort points (serving {unique_regions} regions) "
                        f"but only has capacity for {max_capacity}"
                    )

            except Exception as e:
                print(f"Warning: Error validating facility {facility_name}: {e}")
                continue

        if capacity_warnings:
            print("Sort capacity warnings (minimum regional requirements):")
            for warning in capacity_warnings[:5]:  # Show first 5
                print(f"  â€¢ {warning}")
            if len(capacity_warnings) > 5:
                print(f"  â€¢ ... and {len(capacity_warnings) - 5} more facilities")

            # Make this a warning instead of hard failure for now
            print("âš ï¸  These facilities may need capacity expansion for full optimization")
            print("    Continuing with current capacity constraints...")
        else:
            print("âœ… Sort capacity validation passed - minimum regional requirements met")

    except Exception as e:
        print(f"Warning: Sort capacity validation error: {e}")
        # Don't fail the entire process for validation errors


def calculate_containerization_costs(od_selected: pd.DataFrame, facilities: pd.DataFrame,
                                     mileage_bands: pd.DataFrame, costs: dict,
                                     timing_kv: dict) -> pd.DataFrame:
    """
    Bulletproof cost calculation with comprehensive error handling.
    """
    try:
        if od_selected.empty:
            return pd.DataFrame()

        results = []
        sort_points_per_dest = int(timing_kv.get('sort_points_per_destination', 2))

        # Create facility lookup
        fac_lookup = {}
        try:
            for _, fac in facilities.iterrows():
                fac_lookup[fac['facility_name']] = fac.to_dict()
        except Exception as e:
            print(f"Warning: Error creating facility lookup: {e}")
            return pd.DataFrame()

        for _, od in od_selected.iterrows():
            try:
                origin_name = od['origin']
                dest_name = od['dest']
                pkgs_day = float(od.get('pkgs_day', 0))

                # Get facility info safely
                origin_fac = fac_lookup.get(origin_name)
                dest_fac = fac_lookup.get(dest_name)

                if not origin_fac or not dest_fac:
                    continue

                od_pair_id = f"{origin_name}_{dest_name}"

                # Calculate costs for each containerization level
                cost_data = {
                    'od_pair_id': od_pair_id,
                    'origin': origin_name,
                    'dest': dest_name,
                    'pkgs_day': pkgs_day,
                }

                # Simple cost calculation for each level
                for level in ['region', 'market', 'sort_group']:
                    try:
                        cost, sort_points = _calculate_level_cost_safe(
                            origin_fac, dest_fac, pkgs_day, level,
                            facilities, mileage_bands, costs, sort_points_per_dest
                        )
                        cost_data[f'{level}_cost'] = cost
                        cost_data[f'{level}_sort_points'] = sort_points
                    except Exception as e:
                        print(f"Warning: Error calculating {level} cost for {od_pair_id}: {e}")
                        # Use default values
                        cost_data[f'{level}_cost'] = pkgs_day * 2.0  # Default cost
                        cost_data[f'{level}_sort_points'] = sort_points_per_dest

                results.append(cost_data)

            except Exception as e:
                print(f"Warning: Error processing OD pair: {e}")
                continue

        return pd.DataFrame(results)

    except Exception as e:
        print(f"Error in calculate_containerization_costs: {e}")
        return pd.DataFrame()


def _calculate_level_cost_safe(origin_fac: dict, dest_fac: dict, pkgs_day: float,
                               level: str, facilities: pd.DataFrame, mileage_bands: pd.DataFrame,
                               costs: dict, sort_points_per_dest: int) -> Tuple[float, int]:
    """Safe cost calculation with error handling."""

    try:
        # Default values
        base_cost = pkgs_day * 1.5  # $1.50 per package baseline
        sort_points_needed = sort_points_per_dest

        # Determine sort points needed based on containerization level
        if level == 'region':
            # Region: Least granular, baseline sort points
            sort_points_needed = sort_points_per_dest
        elif level == 'market':
            # Market: Middle granularity, more sort points
            sort_points_needed = sort_points_per_dest * 2
        elif level == 'sort_group':
            # Sort group: Most granular, maximum sort points
            sort_groups = dest_fac.get('last_mile_sort_groups_count', 4)
            sort_points_needed = int(sort_groups) * sort_points_per_dest

        # Simple distance-based cost calculation
        try:
            distance = haversine_miles(
                float(origin_fac['lat']), float(origin_fac['lon']),
                float(dest_fac['lat']), float(dest_fac['lon'])
            )

            # Distance-based cost modifier (deeper containerization saves more on longer routes)
            if level == 'region':
                cost_multiplier = 1.0  # Baseline
            elif level == 'market':
                cost_multiplier = 0.95 if distance > 500 else 1.0  # Small savings for long routes
            else:  # sort_group
                cost_multiplier = 0.85 if distance > 1000 else 0.95  # Bigger savings for very long routes

            final_cost = base_cost * cost_multiplier

        except Exception as e:
            print(f"Warning: Distance calculation error: {e}")
            final_cost = base_cost

        # Add processing costs
        sort_cost = pkgs_day * float(costs.get('sort_cost_per_pkg', 0.5))
        setup_cost = sort_points_needed * float(costs.get('sort_setup_cost_per_point', 0.0))

        total_cost = final_cost + sort_cost + setup_cost

        return total_cost, sort_points_needed

    except Exception as e:
        print(f"Warning: Cost calculation error: {e}")
        return pkgs_day * 2.0, sort_points_per_dest  # Safe defaults


def optimize_sort_allocation(cost_analysis: pd.DataFrame, facilities: pd.DataFrame,
                             timing_kv: dict) -> Dict[str, str]:
    """
    Bulletproof optimization with comprehensive error handling.
    """
    try:
        if cost_analysis.empty:
            return {}

        # Calculate efficiency for each opportunity
        opportunities = []

        for _, row in cost_analysis.iterrows():
            try:
                od_pair_id = row['od_pair_id']
                baseline_cost = row.get('region_cost', 0)

                # Check market and sort_group levels against region baseline
                for level in ['market', 'sort_group']:
                    try:
                        cost = row.get(f'{level}_cost', baseline_cost)
                        sort_points = row.get(f'{level}_sort_points', 2)
                        baseline_points = row.get('region_sort_points', 2)

                        incremental_sort_points = sort_points - baseline_points
                        cost_savings = baseline_cost - cost

                        if incremental_sort_points > 0 and cost_savings > 0:
                            efficiency = cost_savings / incremental_sort_points

                            opportunities.append({
                                'od_pair_id': od_pair_id,
                                'origin': row['origin'],
                                'level': level,
                                'cost_savings': cost_savings,
                                'incremental_sort_points': incremental_sort_points,
                                'efficiency': efficiency,
                                'pkgs_day': row.get('pkgs_day', 0)
                            })
                    except Exception as e:
                        print(f"Warning: Error processing {level} for {od_pair_id}: {e}")
                        continue

            except Exception as e:
                print(f"Warning: Error processing row in optimization: {e}")
                continue

        if not opportunities:
            print("Warning: No optimization opportunities found")
            return {row['od_pair_id']: 'region' for _, row in cost_analysis.iterrows()}

        # Sort by efficiency
        opportunities.sort(key=lambda x: x.get('efficiency', 0), reverse=True)

        # Simple capacity calculation
        facility_capacity = {}
        sort_points_per_dest = int(timing_kv.get('sort_points_per_destination', 2))

        try:
            for _, facility in facilities[facilities['type'].isin(['hub', 'hybrid'])].iterrows():
                facility_name = facility['facility_name']
                max_capacity = facility.get('max_sort_points_capacity')

                if pd.isna(max_capacity):
                    facility_capacity[facility_name] = 1000  # Unlimited capacity
                else:
                    max_capacity = int(max_capacity)

                    # Calculate minimum required (at region level)
                    facility_ods = cost_analysis[cost_analysis['origin'] == facility_name]
                    min_required = len(facility_ods) * sort_points_per_dest  # This should be region-level

                    available = max_capacity - min_required
                    facility_capacity[facility_name] = max(0, available)

        except Exception as e:
            print(f"Warning: Error calculating facility capacity: {e}")
            # Default to unlimited capacity
            for _, facility in facilities.iterrows():
                facility_capacity[facility['facility_name']] = 1000

        # Greedy allocation
        allocation = {row['od_pair_id']: 'region' for _, row in cost_analysis.iterrows()}

        allocated_count = 0
        for opp in opportunities[:50]:  # Limit to top 50 opportunities for performance
            try:
                facility = opp['origin']
                needed = opp['incremental_sort_points']

                if facility_capacity.get(facility, 0) >= needed:
                    allocation[opp['od_pair_id']] = opp['level']
                    facility_capacity[facility] -= needed
                    allocated_count += 1

                    if allocated_count <= 10:  # Only print first 10 allocations
                        print(f"âœ… Allocated {opp['level']} to {opp['od_pair_id']}: "
                              f"${opp['cost_savings']:.0f}/day savings")

            except Exception as e:
                print(f"Warning: Error in allocation: {e}")
                continue

        print(f"ðŸŽ¯ Sort optimization complete: {allocated_count} routes optimized")
        return allocation

    except Exception as e:
        print(f"Error in optimize_sort_allocation: {e}")
        # Return safe default allocation
        if not cost_analysis.empty:
            return {row['od_pair_id']: 'region' for _, row in cost_analysis.iterrows()}
        return {}


def apply_sort_allocation(od_selected: pd.DataFrame, allocation: Dict[str, str],
                          cost_analysis: pd.DataFrame, facilities: pd.DataFrame) -> pd.DataFrame:
    """
    Bulletproof allocation application with comprehensive error handling.
    """
    try:
        if od_selected.empty:
            return od_selected

        od_result = od_selected.copy()

        # Create od_pair_id safely
        if 'origin' in od_result.columns and 'dest' in od_result.columns:
            od_result['od_pair_id'] = od_result['origin'].astype(str) + '_' + od_result['dest'].astype(str)
        else:
            print("Warning: Cannot create od_pair_id - missing origin/dest columns")
            return od_result

        # Apply allocation decisions
        od_result['containerization_level'] = od_result['od_pair_id'].map(allocation)
        od_result['containerization_level'] = od_result['containerization_level'].fillna('region')

        # Add sort points safely
        try:
            if not cost_analysis.empty:
                cost_lookup = cost_analysis.set_index('od_pair_id')
                od_result['sort_points_used'] = od_result.apply(
                    lambda row: _get_sort_points_safe(row, cost_lookup), axis=1
                )
            else:
                od_result['sort_points_used'] = 2  # Default
        except Exception as e:
            print(f"Warning: Error adding sort points: {e}")
            od_result['sort_points_used'] = 2

        # Add efficiency score safely
        try:
            od_result['containerization_efficiency_score'] = od_result.apply(
                lambda row: _calculate_efficiency_score_safe(row, cost_analysis), axis=1
            )
        except Exception as e:
            print(f"Warning: Error calculating efficiency scores: {e}")
            od_result['containerization_efficiency_score'] = 0

        return od_result

    except Exception as e:
        print(f"Error in apply_sort_allocation: {e}")
        return od_selected


def _get_sort_points_safe(row: pd.Series, cost_lookup: pd.DataFrame) -> int:
    """Safely get sort points for a row."""
    try:
        od_pair_id = row['od_pair_id']
        level = row['containerization_level']

        if od_pair_id in cost_lookup.index:
            return int(cost_lookup.loc[od_pair_id, f"{level}_sort_points"])
        return 2  # Default
    except:
        return 2


def _calculate_efficiency_score_safe(row: pd.Series, cost_analysis: pd.DataFrame) -> float:
    """Safely calculate efficiency score."""
    try:
        if cost_analysis.empty:
            return 0.0

        od_pair_id = row['od_pair_id']
        level = row['containerization_level']

        cost_row = cost_analysis[cost_analysis['od_pair_id'] == od_pair_id]
        if cost_row.empty:
            return 0.0

        cost_row = cost_row.iloc[0]
        region_cost = cost_row.get('region_cost', 0)
        level_cost = cost_row.get(f'{level}_cost', region_cost)
        sort_points = cost_row.get(f'{level}_sort_points', 1)

        cost_savings = region_cost - level_cost
        return cost_savings / max(sort_points, 1) if sort_points > 0 else 0.0

    except:
        return 0.0


def summarize_sort_allocation(od_selected: pd.DataFrame, cost_analysis: pd.DataFrame,
                              allocation: Dict[str, str]) -> pd.DataFrame:
    """
    Bulletproof summary with comprehensive error handling.
    """
    try:
        if not allocation or cost_analysis.empty:
            return pd.DataFrame()

        summary_data = []

        for od_pair_id, level in allocation.items():
            try:
                cost_row = cost_analysis[cost_analysis['od_pair_id'] == od_pair_id]
                if cost_row.empty:
                    continue

                cost_row = cost_row.iloc[0]

                baseline_cost = cost_row.get('region_cost', 0)
                actual_cost = cost_row.get(f'{level}_cost', baseline_cost)
                cost_savings = max(0, baseline_cost - actual_cost)  # Ensure non-negative
                sort_points = cost_row.get(f'{level}_sort_points', 2)
                efficiency_score = cost_savings / max(sort_points, 1)

                summary_data.append({
                    'od_pair_id': od_pair_id,
                    'origin': cost_row.get('origin', ''),
                    'dest': cost_row.get('dest', ''),
                    'pkgs_day': cost_row.get('pkgs_day', 0),
                    'containerization_level': level,
                    'daily_cost_savings': cost_savings,
                    'sort_points_used': sort_points,
                    'efficiency_score': efficiency_score,
                })

            except Exception as e:
                print(f"Warning: Error summarizing {od_pair_id}: {e}")
                continue

        summary = pd.DataFrame(summary_data)

        if not summary.empty:
            total_savings = summary['daily_cost_savings'].sum()
            total_points = summary['sort_points_used'].sum()

            print(f"\n=== SORT ALLOCATION SUMMARY ===")
            print(f"Routes optimized: {len(summary)}")
            print(f"Total daily cost savings: ${total_savings:,.0f}")
            print(f"Total sort points used: {total_points:,.0f}")

            if total_points > 0:
                print(f"Average efficiency: ${total_savings / total_points:.0f}/point/day")

            # Level breakdown
            if 'containerization_level' in summary.columns:
                level_summary = summary.groupby('containerization_level').agg({
                    'od_pair_id': 'count',
                    'pkgs_day': 'sum',
                    'daily_cost_savings': 'sum'
                })
                print(f"\nAllocation by level:")
                for level, row in level_summary.iterrows():
                    print(
                        f"  {level}: {row['od_pair_id']} routes, {row['pkgs_day']:,.0f} pkgs/day, ${row['daily_cost_savings']:,.0f} savings")

        return summary

    except Exception as e:
        print(f"Error in summarize_sort_allocation: {e}")
        return pd.DataFrame()